{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIRGdFExTMaA"
   },
   "source": [
    "# **TIPS: Text-Induced Pose Synthesis**\n",
    "\n",
    "This notebook demonstrates the inference pipeline of TIPS.\n",
    "\n",
    "*Accepted in The European Conference on Computer Vision (ECCV) 2022.*\n",
    "\n",
    "https://prasunroy.github.io/tips\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llQwjAlyVUGg"
   },
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIecdeBgX1OT"
   },
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xi6AyqVYPiY"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R67U4fbTYzMx"
   },
   "outputs": [],
   "source": [
    "from tips import TIPS\n",
    "from tips import visualize_skeletons, visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GF5ZPPY_Y4GD"
   },
   "source": [
    "Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZ8GBlzhZIa2"
   },
   "outputs": [],
   "source": [
    "prng = np.random.default_rng(1)\n",
    "\n",
    "ckpt_text2pose = './checkpoints/text2pose_75000.pth'\n",
    "ckpt_refinenet = './checkpoints/refinenet_100.pth'\n",
    "ckpt_pose2pose = './checkpoints/pose2pose_260500.pth'\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "data_root = './data'\n",
    "save_root_df2df = f'./output/{timestamp}/df2df'\n",
    "save_root_df2rw = f'./output/{timestamp}/df2rw'\n",
    "\n",
    "keypoints = pd.read_csv('./data/keypoints.csv', index_col='file_id')\n",
    "encodings = pd.read_csv('./data/encodings.csv', index_col='file_id')\n",
    "img_descs = pd.read_csv('./data/descriptions.csv', index_col='file_id')\n",
    "img_pairs_df2df = pd.read_csv('./data/img_pairs_df2df.csv')\n",
    "img_pairs_df2rw = pd.read_csv('./data/img_pairs_df2rw.csv')\n",
    "\n",
    "font = './data/FreeMono.ttf'\n",
    "bbox = (40, 0, 216, 256)\n",
    "\n",
    "file_id = lambda path: os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "if not os.path.isdir(save_root_df2df): os.makedirs(save_root_df2df)\n",
    "if not os.path.isdir(save_root_df2rw): os.makedirs(save_root_df2rw)\n",
    "\n",
    "# Sample a random noise vector from a standard normal distribution\n",
    "z = prng.normal(size=128).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pod3SkPOaFGk"
   },
   "source": [
    "## Initialize TIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdMxzLtGaN2w"
   },
   "outputs": [],
   "source": [
    "tips = TIPS(ckpt_text2pose, ckpt_refinenet, ckpt_pose2pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-AOEIS94Qok"
   },
   "source": [
    "## Generation with DeepFashion targets (*within distribution*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lI4ExM9uXUf"
   },
   "source": [
    "#### Load a random test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xAj3GmX2vMCl"
   },
   "outputs": [],
   "source": [
    "index = np.random.randint(0, len(img_pairs_df2df))\n",
    "\n",
    "fpA = img_pairs_df2df.iloc[index].imgA\n",
    "fpB = img_pairs_df2df.iloc[index].imgB\n",
    "\n",
    "source_image = Image.open(f'{data_root}/{fpA}')\n",
    "target_image = Image.open(f'{data_root}/{fpB}')\n",
    "\n",
    "source_keypoints = keypoints.loc[file_id(fpA)].values[2:38].astype(np.int32)\n",
    "target_keypoints = keypoints.loc[file_id(fpB)].values[2:38].astype(np.int32)\n",
    "\n",
    "source_text_encoding = encodings.loc[file_id(fpA)].values[0:84].astype(np.float32)\n",
    "target_text_encoding = encodings.loc[file_id(fpB)].values[0:84].astype(np.float32)\n",
    "\n",
    "source_text_description = img_descs.loc[file_id(fpA)].description\n",
    "target_text_description = img_descs.loc[file_id(fpB)].description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ske1_3M47slz"
   },
   "source": [
    "#### Keypoints guided benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOEyuU4Q70Pj"
   },
   "outputs": [],
   "source": [
    "generated_image = tips.benchmark(source_image, source_keypoints, target_keypoints)\n",
    "\n",
    "images_dict = {\n",
    "    'iA': source_image.crop(bbox),\n",
    "    'iB': target_image.crop(bbox),\n",
    "    'iB_k': generated_image.crop(bbox),\n",
    "    'kA': Image.fromarray(visualize_skeletons([source_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
    "    'kB': Image.fromarray(visualize_skeletons([target_keypoints], head_color=(100, 255, 100))).crop(bbox)\n",
    "}\n",
    "\n",
    "layout = [['iA', 'kA', 'iB', 'kB', 'iB_k']]\n",
    "\n",
    "grid = visualize(images_dict, layout, True, font)\n",
    "\n",
    "display(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rC3wDS3H2WXe"
   },
   "source": [
    "#### Partially text guided pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PdGCFL0y2rnQ"
   },
   "outputs": [],
   "source": [
    "out1 = tips.pipeline(source_image, source_keypoints, target_text_encoding, z)\n",
    "\n",
    "images_dict = {\n",
    "    'iA': source_image.crop(bbox),\n",
    "    'iB': target_image.crop(bbox),\n",
    "    'iB_c': out1['iB_c'].crop(bbox),\n",
    "    'iB_f': out1['iB_f'].crop(bbox),\n",
    "    'kA': Image.fromarray(visualize_skeletons([source_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
    "    'kB_c': Image.fromarray(visualize_skeletons([out1['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
    "    'kB_f': Image.fromarray(visualize_skeletons([out1['kB_f']], head_color=(100, 100, 255))).crop(bbox)\n",
    "}\n",
    "\n",
    "layout = [['iA', 'kA', 'iB', 'kB_c', 'iB_c'], ['iA', 'kA', 'iB', 'kB_f', 'iB_f']]\n",
    "\n",
    "grid = visualize(images_dict, layout, True, font)\n",
    "\n",
    "display(grid)\n",
    "print('\\nTarget description:\\n\\n' + target_text_description.replace('. ', '.\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAEc3Pwu68en"
   },
   "source": [
    "#### Fully text guided pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A68vTs717Dta"
   },
   "outputs": [],
   "source": [
    "out2 = tips.pipeline_full(source_image, source_text_encoding, target_text_encoding, z)\n",
    "\n",
    "images_dict = {\n",
    "    'iA': source_image.crop(bbox),\n",
    "    'iB': target_image.crop(bbox),\n",
    "    'iB_c': out2['iB_c'].crop(bbox),\n",
    "    'iB_f': out2['iB_f'].crop(bbox),\n",
    "    'kA_c': Image.fromarray(visualize_skeletons([out2['kA_c']], head_color=(255, 100, 100))).crop(bbox),\n",
    "    'kA_f': Image.fromarray(visualize_skeletons([out2['kA_f']], head_color=(100, 100, 255))).crop(bbox),\n",
    "    'kB_c': Image.fromarray(visualize_skeletons([out2['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
    "    'kB_f': Image.fromarray(visualize_skeletons([out2['kB_f']], head_color=(100, 100, 255))).crop(bbox)\n",
    "}\n",
    "\n",
    "layout = [['iA', 'kA_c', 'iB', 'kB_c', 'iB_c'], ['iA', 'kA_f', 'iB', 'kB_f', 'iB_f']]\n",
    "\n",
    "grid = visualize(images_dict, layout, True, font)\n",
    "\n",
    "display(grid)\n",
    "print('\\nSource description:\\n\\n' + source_text_description.replace('. ', '.\\n'))\n",
    "print('\\nTarget description:\\n\\n' + target_text_description.replace('. ', '.\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhC_maow-hbD"
   },
   "source": [
    "## Generation with Real World targets (*out of distribution*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPdVn2xr-hbY"
   },
   "source": [
    "#### Load a random test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwDWzqpu-hbZ"
   },
   "outputs": [],
   "source": [
    "index = np.random.randint(0, len(img_pairs_df2rw))\n",
    "\n",
    "fpA = img_pairs_df2rw.iloc[index].imgA\n",
    "fpB = img_pairs_df2rw.iloc[index].imgB\n",
    "\n",
    "source_image = Image.open(f'{data_root}/{fpA}')\n",
    "target_image = Image.open(f'{data_root}/{fpB}')\n",
    "\n",
    "source_keypoints = keypoints.loc[file_id(fpA)].values[2:38].astype(np.int32)\n",
    "target_keypoints = keypoints.loc[file_id(fpB)].values[2:38].astype(np.int32)\n",
    "\n",
    "source_text_encoding = encodings.loc[file_id(fpA)].values[0:84].astype(np.float32)\n",
    "target_text_encoding = encodings.loc[file_id(fpB)].values[0:84].astype(np.float32)\n",
    "\n",
    "source_text_description = img_descs.loc[file_id(fpA)].description\n",
    "target_text_description = img_descs.loc[file_id(fpB)].description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpeZ-tg9-hbb"
   },
   "source": [
    "#### Keypoints guided benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dz_19CRq-hbc"
   },
   "outputs": [],
   "source": [
    "generated_image = tips.benchmark(source_image, source_keypoints, target_keypoints)\n",
    "\n",
    "images_dict = {\n",
    "    'iA': source_image.crop(bbox),\n",
    "    'iB': target_image.crop(bbox),\n",
    "    'iB_k': generated_image.crop(bbox),\n",
    "    'kA': Image.fromarray(visualize_skeletons([source_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
    "    'kB': Image.fromarray(visualize_skeletons([target_keypoints], head_color=(100, 255, 100))).crop(bbox)\n",
    "}\n",
    "\n",
    "layout = [['iA', 'kA', 'iB', 'kB', 'iB_k']]\n",
    "\n",
    "grid = visualize(images_dict, layout, True, font)\n",
    "\n",
    "display(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgYMrH9d-hbd"
   },
   "source": [
    "#### Partially text guided pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hE1skWtc-hbd"
   },
   "outputs": [],
   "source": [
    "out1 = tips.pipeline(source_image, source_keypoints, target_text_encoding, z)\n",
    "\n",
    "images_dict = {\n",
    "    'iA': source_image.crop(bbox),\n",
    "    'iB': target_image.crop(bbox),\n",
    "    'iB_c': out1['iB_c'].crop(bbox),\n",
    "    'iB_f': out1['iB_f'].crop(bbox),\n",
    "    'kA': Image.fromarray(visualize_skeletons([source_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
    "    'kB_c': Image.fromarray(visualize_skeletons([out1['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
    "    'kB_f': Image.fromarray(visualize_skeletons([out1['kB_f']], head_color=(100, 100, 255))).crop(bbox)\n",
    "}\n",
    "\n",
    "layout = [['iA', 'kA', 'iB', 'kB_c', 'iB_c'], ['iA', 'kA', 'iB', 'kB_f', 'iB_f']]\n",
    "\n",
    "grid = visualize(images_dict, layout, True, font)\n",
    "\n",
    "display(grid)\n",
    "print('\\nTarget description:\\n\\n' + target_text_description.replace('. ', '.\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJ0iHUeq-hbe"
   },
   "source": [
    "#### Fully text guided pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-CHrbRo-hbf"
   },
   "outputs": [],
   "source": [
    "out2 = tips.pipeline_full(source_image, source_text_encoding, target_text_encoding, z)\n",
    "\n",
    "images_dict = {\n",
    "    'iA': source_image.crop(bbox),\n",
    "    'iB': target_image.crop(bbox),\n",
    "    'iB_c': out2['iB_c'].crop(bbox),\n",
    "    'iB_f': out2['iB_f'].crop(bbox),\n",
    "    'kA_c': Image.fromarray(visualize_skeletons([out2['kA_c']], head_color=(255, 100, 100))).crop(bbox),\n",
    "    'kA_f': Image.fromarray(visualize_skeletons([out2['kA_f']], head_color=(100, 100, 255))).crop(bbox),\n",
    "    'kB_c': Image.fromarray(visualize_skeletons([out2['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
    "    'kB_f': Image.fromarray(visualize_skeletons([out2['kB_f']], head_color=(100, 100, 255))).crop(bbox)\n",
    "}\n",
    "\n",
    "layout = [['iA', 'kA_c', 'iB', 'kB_c', 'iB_c'], ['iA', 'kA_f', 'iB', 'kB_f', 'iB_f']]\n",
    "\n",
    "grid = visualize(images_dict, layout, True, font)\n",
    "\n",
    "display(grid)\n",
    "print('\\nSource description:\\n\\n' + source_text_description.replace('. ', '.\\n'))\n",
    "print('\\nTarget description:\\n\\n' + target_text_description.replace('. ', '.\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvHwRacqEGBO"
   },
   "source": [
    "## Generate all *within distribution* samples\n",
    "\n",
    "This will generate all *within distribution* test samples for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ie7X3hK9FPY5"
   },
   "outputs": [],
   "source": [
    "layout = [\n",
    "    ['iA', 'kA',    'iB', 'kB',    'iB_k0'],\n",
    "    ['iA', 'kA',    'iB', 'kB_c1', 'iB_c1'],\n",
    "    ['iA', 'kA',    'iB', 'kB_f1', 'iB_f1'],\n",
    "    ['iA', 'kA_c2', 'iB', 'kB_c2', 'iB_c2'],\n",
    "    ['iA', 'kA_f2', 'iB', 'kB_f2', 'iB_f2']\n",
    "]\n",
    "\n",
    "for i in range(len(img_pairs_df2df)):\n",
    "    fpA = img_pairs_df2df.iloc[i].imgA\n",
    "    fpB = img_pairs_df2df.iloc[i].imgB\n",
    "    \n",
    "    source_text_encoding = encodings.loc[file_id(fpA)].values[0:84].astype(np.float32)\n",
    "    target_text_encoding = encodings.loc[file_id(fpB)].values[0:84].astype(np.float32)\n",
    "    \n",
    "    source_keypoints = keypoints.loc[file_id(fpA)].values[2:38].astype(np.int32)\n",
    "    target_keypoints = keypoints.loc[file_id(fpB)].values[2:38].astype(np.int32)\n",
    "    \n",
    "    source_image = Image.open(f'{data_root}/{fpA}')\n",
    "    target_image = Image.open(f'{data_root}/{fpB}')\n",
    "    \n",
    "    iB_k = tips.benchmark(source_image, source_keypoints, target_keypoints)\n",
    "    out1 = tips.pipeline(source_image, source_keypoints, target_text_encoding, z)\n",
    "    out2 = tips.pipeline_full(source_image, source_text_encoding, target_text_encoding, z)\n",
    "    \n",
    "    images_dict = {\n",
    "        'iA': source_image.crop(bbox),\n",
    "        'iB': target_image.crop(bbox),\n",
    "        'iB_k0': iB_k.crop(bbox),\n",
    "        'iB_c1': out1['iB_c'].crop(bbox),\n",
    "        'iB_f1': out1['iB_f'].crop(bbox),\n",
    "        'iB_c2': out2['iB_c'].crop(bbox),\n",
    "        'iB_f2': out2['iB_f'].crop(bbox),\n",
    "        'kA': Image.fromarray(visualize_skeletons([source_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
    "        'kB': Image.fromarray(visualize_skeletons([target_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
    "        'kA_c2': Image.fromarray(visualize_skeletons([out2['kA_c']], head_color=(255, 100, 100))).crop(bbox),\n",
    "        'kA_f2': Image.fromarray(visualize_skeletons([out2['kA_f']], head_color=(100, 100, 255))).crop(bbox),\n",
    "        'kB_c1': Image.fromarray(visualize_skeletons([out1['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
    "        'kB_f1': Image.fromarray(visualize_skeletons([out1['kB_f']], head_color=(100, 100, 255))).crop(bbox),\n",
    "        'kB_c2': Image.fromarray(visualize_skeletons([out2['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
    "        'kB_f2': Image.fromarray(visualize_skeletons([out2['kB_f']], head_color=(100, 100, 255))).crop(bbox),\n",
    "    }\n",
    "    \n",
    "    grid = visualize(images_dict, layout, True, font)\n",
    "    grid.save(f'{save_root_df2df}/{file_id(fpA)}____{file_id(fpB)}.png')\n",
    "    print(f'\\r[DF2DF] Testing TIPS inference pipeline... {i+1}/{len(img_pairs_df2df)}', end='')\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcQ16H0BJNvn"
   },
   "source": [
    "## Generate all *out of distribution* samples\n",
    "\n",
    "This will generate all *out of distribution* test samples for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oiaNr0FJNv9"
   },
   "outputs": [],
   "source": [
    "layout = [\n",
    "    ['iA', 'kA',    'iB', 'kB',    'iB_k0'],\n",
    "    ['iA', 'kA',    'iB', 'kB_c1', 'iB_c1'],\n",
    "    ['iA', 'kA',    'iB', 'kB_f1', 'iB_f1'],\n",
    "    ['iA', 'kA_c2', 'iB', 'kB_c2', 'iB_c2'],\n",
    "    ['iA', 'kA_f2', 'iB', 'kB_f2', 'iB_f2']\n",
    "]\n",
    "\n",
    "for i in range(len(img_pairs_df2rw)):\n",
    "    fpA = img_pairs_df2rw.iloc[i].imgA\n",
    "    fpB = img_pairs_df2rw.iloc[i].imgB\n",
    "    \n",
    "    source_text_encoding = encodings.loc[file_id(fpA)].values[0:84].astype(np.float32)\n",
    "    target_text_encoding = encodings.loc[file_id(fpB)].values[0:84].astype(np.float32)\n",
    "    \n",
    "    source_keypoints = keypoints.loc[file_id(fpA)].values[2:38].astype(np.int32)\n",
    "    target_keypoints = keypoints.loc[file_id(fpB)].values[2:38].astype(np.int32)\n",
    "    \n",
    "    source_image = Image.open(f'{data_root}/{fpA}')\n",
    "    target_image = Image.open(f'{data_root}/{fpB}')\n",
    "    \n",
    "    iB_k = tips.benchmark(source_image, source_keypoints, target_keypoints)\n",
    "    out1 = tips.pipeline(source_image, source_keypoints, target_text_encoding, z)\n",
    "    out2 = tips.pipeline_full(source_image, source_text_encoding, target_text_encoding, z)\n",
    "    \n",
    "    images_dict = {\n",
    "        'iA': source_image.crop(bbox),\n",
    "        'iB': target_image.crop(bbox),\n",
    "        'iB_k0': iB_k.crop(bbox),\n",
    "        'iB_c1': out1['iB_c'].crop(bbox),\n",
    "        'iB_f1': out1['iB_f'].crop(bbox),\n",
    "        'iB_c2': out2['iB_c'].crop(bbox),\n",
    "        'iB_f2': out2['iB_f'].crop(bbox),\n",
    "        'kA': Image.fromarray(visualize_skeletons([source_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
    "        'kB': Image.fromarray(visualize_skeletons([target_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
    "        'kA_c2': Image.fromarray(visualize_skeletons([out2['kA_c']], head_color=(255, 100, 100))).crop(bbox),\n",
    "        'kA_f2': Image.fromarray(visualize_skeletons([out2['kA_f']], head_color=(100, 100, 255))).crop(bbox),\n",
    "        'kB_c1': Image.fromarray(visualize_skeletons([out1['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
    "        'kB_f1': Image.fromarray(visualize_skeletons([out1['kB_f']], head_color=(100, 100, 255))).crop(bbox),\n",
    "        'kB_c2': Image.fromarray(visualize_skeletons([out2['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
    "        'kB_f2': Image.fromarray(visualize_skeletons([out2['kB_f']], head_color=(100, 100, 255))).crop(bbox),\n",
    "    }\n",
    "    \n",
    "    grid = visualize(images_dict, layout, True, font)\n",
    "    grid.save(f'{save_root_df2rw}/{file_id(fpA)}____{file_id(fpB)}.png')\n",
    "    print(f'\\r[DF2RW] Testing TIPS inference pipeline... {i+1}/{len(img_pairs_df2rw)}', end='')\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IH66_yKYR6v6"
   },
   "source": [
    "# ***Thank you for checking out TIPS!***\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TIPS_demo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
