{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TIPS_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIRGdFExTMaA"
      },
      "source": [
        "# **TIPS: Text-Induced Pose Synthesis**\n",
        "\n",
        "This notebook demonstrates the inference pipeline of TIPS.\n",
        "\n",
        "*Accepted in The European Conference on Computer Vision (ECCV) 2022.*\n",
        "\n",
        "https://prasunroy.github.io/tips\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llQwjAlyVUGg"
      },
      "source": [
        "## Getting started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGRaCQXz2K6A"
      },
      "source": [
        "Download and extract the required resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks3itvIuVD9z"
      },
      "source": [
        "!rm * -Rf\n",
        "!wget 'https://drive.google.com/uc?id=1zTG9M06ckW0z4MvJks3-JSC8sJguiZJH&confirm=t&uuid=eff55096-c74c-413e-874f-c8ca2ea4cb27&at=ALgDtsy0Pr78iHzB8TK5eTUpy5j2:1676916580137' -O tips.zip\n",
        "!unzip -oq tips.zip && rm tips.zip\n",
        "!ls -lah\n",
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIecdeBgX1OT"
      },
      "source": [
        "Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xi6AyqVYPiY"
      },
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R67U4fbTYzMx"
      },
      "source": [
        "from tips import TIPS\n",
        "from tips import visualize_skeletons, visualize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzBoq8b2IPw4"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF5ZPPY_Y4GD"
      },
      "source": [
        "Configure environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ8GBlzhZIa2"
      },
      "source": [
        "prng = np.random.default_rng(1)\n",
        "\n",
        "ckpt_text2pose = './checkpoints/text2pose_75000.pth'\n",
        "ckpt_refinenet = './checkpoints/refinenet_100.pth'\n",
        "ckpt_pose2pose = './checkpoints/pose2pose_260500.pth'\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
        "\n",
        "data_root = './data'\n",
        "save_root_df2df = f'./output/{timestamp}/df2df'\n",
        "save_root_df2rw = f'./output/{timestamp}/df2rw'\n",
        "\n",
        "keypoints = pd.read_csv('./data/keypoints.csv', index_col='file_id')\n",
        "encodings = pd.read_csv('./data/encodings.csv', index_col='file_id')\n",
        "img_descs = pd.read_csv('./data/descriptions.csv', index_col='file_id')\n",
        "img_pairs_df2df = pd.read_csv('./data/img_pairs_df2df.csv')\n",
        "img_pairs_df2rw = pd.read_csv('./data/img_pairs_df2rw.csv')\n",
        "\n",
        "font = './data/FreeMono.ttf'\n",
        "bbox = (40, 0, 216, 256)\n",
        "\n",
        "file_id = lambda path: os.path.splitext(os.path.basename(path))[0]\n",
        "\n",
        "if not os.path.isdir(save_root_df2df): os.makedirs(save_root_df2df)\n",
        "if not os.path.isdir(save_root_df2rw): os.makedirs(save_root_df2rw)\n",
        "\n",
        "# Sample a random noise vector from a standard normal distribution\n",
        "z = prng.normal(size=128).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pod3SkPOaFGk"
      },
      "source": [
        "## Initialize TIPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdMxzLtGaN2w"
      },
      "source": [
        "tips = TIPS(ckpt_text2pose, ckpt_refinenet, ckpt_pose2pose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-AOEIS94Qok"
      },
      "source": [
        "## Generation with DeepFashion targets (*within distribution*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lI4ExM9uXUf"
      },
      "source": [
        "#### Load a random test sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAj3GmX2vMCl"
      },
      "source": [
        "index = np.random.randint(0, len(img_pairs_df2df))\n",
        "\n",
        "fpA = img_pairs_df2df.iloc[index].imgA\n",
        "fpB = img_pairs_df2df.iloc[index].imgB\n",
        "\n",
        "source_image = Image.open(f'{data_root}/{fpA}')\n",
        "target_image = Image.open(f'{data_root}/{fpB}')\n",
        "\n",
        "source_keypoints = keypoints.loc[file_id(fpA)].values[2:38].astype(np.int32)\n",
        "target_keypoints = keypoints.loc[file_id(fpB)].values[2:38].astype(np.int32)\n",
        "\n",
        "source_text_encoding = encodings.loc[file_id(fpA)].values[0:84].astype(np.float32)\n",
        "target_text_encoding = encodings.loc[file_id(fpB)].values[0:84].astype(np.float32)\n",
        "\n",
        "source_text_description = img_descs.loc[file_id(fpA)].description\n",
        "target_text_description = img_descs.loc[file_id(fpB)].description"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ske1_3M47slz"
      },
      "source": [
        "#### Keypoints guided benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOEyuU4Q70Pj"
      },
      "source": [
        "generated_image = tips.benchmark(source_image, source_keypoints, target_keypoints)\n",
        "\n",
        "images_dict = {\n",
        "    'iA': source_image.crop(bbox),\n",
        "    'iB': target_image.crop(bbox),\n",
        "    'iB_k': generated_image.crop(bbox),\n",
        "    'kA': Image.fromarray(visualize_skeletons([source_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
        "    'kB': Image.fromarray(visualize_skeletons([target_keypoints], head_color=(100, 255, 100))).crop(bbox)\n",
        "}\n",
        "\n",
        "layout = [['iA', 'kA', 'iB', 'kB', 'iB_k']]\n",
        "\n",
        "grid = visualize(images_dict, layout, True, font)\n",
        "\n",
        "display(grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC3wDS3H2WXe"
      },
      "source": [
        "#### Partially text guided pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdGCFL0y2rnQ"
      },
      "source": [
        "out1 = tips.pipeline(source_image, source_keypoints, target_text_encoding, z)\n",
        "\n",
        "images_dict = {\n",
        "    'iA': source_image.crop(bbox),\n",
        "    'iB': target_image.crop(bbox),\n",
        "    'iB_c': out1['iB_c'].crop(bbox),\n",
        "    'iB_f': out1['iB_f'].crop(bbox),\n",
        "    'kA': Image.fromarray(visualize_skeletons([source_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
        "    'kB_c': Image.fromarray(visualize_skeletons([out1['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
        "    'kB_f': Image.fromarray(visualize_skeletons([out1['kB_f']], head_color=(100, 100, 255))).crop(bbox)\n",
        "}\n",
        "\n",
        "layout = [['iA', 'kA', 'iB', 'kB_c', 'iB_c'], ['iA', 'kA', 'iB', 'kB_f', 'iB_f']]\n",
        "\n",
        "grid = visualize(images_dict, layout, True, font)\n",
        "\n",
        "display(grid)\n",
        "print('\\nTarget description:\\n\\n' + target_text_description.replace('. ', '.\\n'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAEc3Pwu68en"
      },
      "source": [
        "#### Fully text guided pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A68vTs717Dta"
      },
      "source": [
        "out2 = tips.pipeline_full(source_image, source_text_encoding, target_text_encoding, z)\n",
        "\n",
        "images_dict = {\n",
        "    'iA': source_image.crop(bbox),\n",
        "    'iB': target_image.crop(bbox),\n",
        "    'iB_c': out2['iB_c'].crop(bbox),\n",
        "    'iB_f': out2['iB_f'].crop(bbox),\n",
        "    'kA_c': Image.fromarray(visualize_skeletons([out2['kA_c']], head_color=(255, 100, 100))).crop(bbox),\n",
        "    'kA_f': Image.fromarray(visualize_skeletons([out2['kA_f']], head_color=(100, 100, 255))).crop(bbox),\n",
        "    'kB_c': Image.fromarray(visualize_skeletons([out2['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
        "    'kB_f': Image.fromarray(visualize_skeletons([out2['kB_f']], head_color=(100, 100, 255))).crop(bbox)\n",
        "}\n",
        "\n",
        "layout = [['iA', 'kA_c', 'iB', 'kB_c', 'iB_c'], ['iA', 'kA_f', 'iB', 'kB_f', 'iB_f']]\n",
        "\n",
        "grid = visualize(images_dict, layout, True, font)\n",
        "\n",
        "display(grid)\n",
        "print('\\nSource description:\\n\\n' + source_text_description.replace('. ', '.\\n'))\n",
        "print('\\nTarget description:\\n\\n' + target_text_description.replace('. ', '.\\n'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhC_maow-hbD"
      },
      "source": [
        "## Generation with Real World targets (*out of distribution*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPdVn2xr-hbY"
      },
      "source": [
        "#### Load a random test sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwDWzqpu-hbZ"
      },
      "source": [
        "index = np.random.randint(0, len(img_pairs_df2rw))\n",
        "\n",
        "fpA = img_pairs_df2rw.iloc[index].imgA\n",
        "fpB = img_pairs_df2rw.iloc[index].imgB\n",
        "\n",
        "source_image = Image.open(f'{data_root}/{fpA}')\n",
        "target_image = Image.open(f'{data_root}/{fpB}')\n",
        "\n",
        "source_keypoints = keypoints.loc[file_id(fpA)].values[2:38].astype(np.int32)\n",
        "target_keypoints = keypoints.loc[file_id(fpB)].values[2:38].astype(np.int32)\n",
        "\n",
        "source_text_encoding = encodings.loc[file_id(fpA)].values[0:84].astype(np.float32)\n",
        "target_text_encoding = encodings.loc[file_id(fpB)].values[0:84].astype(np.float32)\n",
        "\n",
        "source_text_description = img_descs.loc[file_id(fpA)].description\n",
        "target_text_description = img_descs.loc[file_id(fpB)].description"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpeZ-tg9-hbb"
      },
      "source": [
        "#### Keypoints guided benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz_19CRq-hbc"
      },
      "source": [
        "generated_image = tips.benchmark(source_image, source_keypoints, target_keypoints)\n",
        "\n",
        "images_dict = {\n",
        "    'iA': source_image.crop(bbox),\n",
        "    'iB': target_image.crop(bbox),\n",
        "    'iB_k': generated_image.crop(bbox),\n",
        "    'kA': Image.fromarray(visualize_skeletons([source_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
        "    'kB': Image.fromarray(visualize_skeletons([target_keypoints], head_color=(100, 255, 100))).crop(bbox)\n",
        "}\n",
        "\n",
        "layout = [['iA', 'kA', 'iB', 'kB', 'iB_k']]\n",
        "\n",
        "grid = visualize(images_dict, layout, True, font)\n",
        "\n",
        "display(grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgYMrH9d-hbd"
      },
      "source": [
        "#### Partially text guided pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE1skWtc-hbd"
      },
      "source": [
        "out1 = tips.pipeline(source_image, source_keypoints, target_text_encoding, z)\n",
        "\n",
        "images_dict = {\n",
        "    'iA': source_image.crop(bbox),\n",
        "    'iB': target_image.crop(bbox),\n",
        "    'iB_c': out1['iB_c'].crop(bbox),\n",
        "    'iB_f': out1['iB_f'].crop(bbox),\n",
        "    'kA': Image.fromarray(visualize_skeletons([source_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
        "    'kB_c': Image.fromarray(visualize_skeletons([out1['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
        "    'kB_f': Image.fromarray(visualize_skeletons([out1['kB_f']], head_color=(100, 100, 255))).crop(bbox)\n",
        "}\n",
        "\n",
        "layout = [['iA', 'kA', 'iB', 'kB_c', 'iB_c'], ['iA', 'kA', 'iB', 'kB_f', 'iB_f']]\n",
        "\n",
        "grid = visualize(images_dict, layout, True, font)\n",
        "\n",
        "display(grid)\n",
        "print('\\nTarget description:\\n\\n' + target_text_description.replace('. ', '.\\n'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ0iHUeq-hbe"
      },
      "source": [
        "#### Fully text guided pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-CHrbRo-hbf"
      },
      "source": [
        "out2 = tips.pipeline_full(source_image, source_text_encoding, target_text_encoding, z)\n",
        "\n",
        "images_dict = {\n",
        "    'iA': source_image.crop(bbox),\n",
        "    'iB': target_image.crop(bbox),\n",
        "    'iB_c': out2['iB_c'].crop(bbox),\n",
        "    'iB_f': out2['iB_f'].crop(bbox),\n",
        "    'kA_c': Image.fromarray(visualize_skeletons([out2['kA_c']], head_color=(255, 100, 100))).crop(bbox),\n",
        "    'kA_f': Image.fromarray(visualize_skeletons([out2['kA_f']], head_color=(100, 100, 255))).crop(bbox),\n",
        "    'kB_c': Image.fromarray(visualize_skeletons([out2['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
        "    'kB_f': Image.fromarray(visualize_skeletons([out2['kB_f']], head_color=(100, 100, 255))).crop(bbox)\n",
        "}\n",
        "\n",
        "layout = [['iA', 'kA_c', 'iB', 'kB_c', 'iB_c'], ['iA', 'kA_f', 'iB', 'kB_f', 'iB_f']]\n",
        "\n",
        "grid = visualize(images_dict, layout, True, font)\n",
        "\n",
        "display(grid)\n",
        "print('\\nSource description:\\n\\n' + source_text_description.replace('. ', '.\\n'))\n",
        "print('\\nTarget description:\\n\\n' + target_text_description.replace('. ', '.\\n'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvHwRacqEGBO"
      },
      "source": [
        "## Generate all *within distribution* samples\n",
        "\n",
        "This will generate all *within distribution* test samples for reproducibility.\n",
        "\n",
        "Note: Output will be compressed and downloaded as a zip archive for offline viewing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie7X3hK9FPY5"
      },
      "source": [
        "layout = [\n",
        "    ['iA', 'kA',    'iB', 'kB',    'iB_k0'],\n",
        "    ['iA', 'kA',    'iB', 'kB_c1', 'iB_c1'],\n",
        "    ['iA', 'kA',    'iB', 'kB_f1', 'iB_f1'],\n",
        "    ['iA', 'kA_c2', 'iB', 'kB_c2', 'iB_c2'],\n",
        "    ['iA', 'kA_f2', 'iB', 'kB_f2', 'iB_f2']\n",
        "]\n",
        "\n",
        "for i in range(len(img_pairs_df2df)):\n",
        "    fpA = img_pairs_df2df.iloc[i].imgA\n",
        "    fpB = img_pairs_df2df.iloc[i].imgB\n",
        "    \n",
        "    source_text_encoding = encodings.loc[file_id(fpA)].values[0:84].astype(np.float32)\n",
        "    target_text_encoding = encodings.loc[file_id(fpB)].values[0:84].astype(np.float32)\n",
        "    \n",
        "    source_keypoints = keypoints.loc[file_id(fpA)].values[2:38].astype(np.int32)\n",
        "    target_keypoints = keypoints.loc[file_id(fpB)].values[2:38].astype(np.int32)\n",
        "    \n",
        "    source_image = Image.open(f'{data_root}/{fpA}')\n",
        "    target_image = Image.open(f'{data_root}/{fpB}')\n",
        "    \n",
        "    iB_k = tips.benchmark(source_image, source_keypoints, target_keypoints)\n",
        "    out1 = tips.pipeline(source_image, source_keypoints, target_text_encoding, z)\n",
        "    out2 = tips.pipeline_full(source_image, source_text_encoding, target_text_encoding, z)\n",
        "    \n",
        "    images_dict = {\n",
        "        'iA': source_image.crop(bbox),\n",
        "        'iB': target_image.crop(bbox),\n",
        "        'iB_k0': iB_k.crop(bbox),\n",
        "        'iB_c1': out1['iB_c'].crop(bbox),\n",
        "        'iB_f1': out1['iB_f'].crop(bbox),\n",
        "        'iB_c2': out2['iB_c'].crop(bbox),\n",
        "        'iB_f2': out2['iB_f'].crop(bbox),\n",
        "        'kA': Image.fromarray(visualize_skeletons([source_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
        "        'kB': Image.fromarray(visualize_skeletons([target_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
        "        'kA_c2': Image.fromarray(visualize_skeletons([out2['kA_c']], head_color=(255, 100, 100))).crop(bbox),\n",
        "        'kA_f2': Image.fromarray(visualize_skeletons([out2['kA_f']], head_color=(100, 100, 255))).crop(bbox),\n",
        "        'kB_c1': Image.fromarray(visualize_skeletons([out1['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
        "        'kB_f1': Image.fromarray(visualize_skeletons([out1['kB_f']], head_color=(100, 100, 255))).crop(bbox),\n",
        "        'kB_c2': Image.fromarray(visualize_skeletons([out2['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
        "        'kB_f2': Image.fromarray(visualize_skeletons([out2['kB_f']], head_color=(100, 100, 255))).crop(bbox),\n",
        "    }\n",
        "    \n",
        "    grid = visualize(images_dict, layout, True, font)\n",
        "    grid.save(f'{save_root_df2df}/{file_id(fpA)}____{file_id(fpB)}.png')\n",
        "    print(f'\\r[DF2DF] Testing TIPS inference pipeline... {i+1}/{len(img_pairs_df2df)}', end='')\n",
        "\n",
        "print('')\n",
        "\n",
        "!zip -rq tips_output_df2df.zip $save_root_df2df\n",
        "\n",
        "files.download('tips_output_df2df.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcQ16H0BJNvn"
      },
      "source": [
        "## Generate all *out of distribution* samples\n",
        "\n",
        "This will generate all *out of distribution* test samples for reproducibility.\n",
        "\n",
        "Note: Output will be compressed and downloaded as a zip archive for offline viewing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oiaNr0FJNv9"
      },
      "source": [
        "layout = [\n",
        "    ['iA', 'kA',    'iB', 'kB',    'iB_k0'],\n",
        "    ['iA', 'kA',    'iB', 'kB_c1', 'iB_c1'],\n",
        "    ['iA', 'kA',    'iB', 'kB_f1', 'iB_f1'],\n",
        "    ['iA', 'kA_c2', 'iB', 'kB_c2', 'iB_c2'],\n",
        "    ['iA', 'kA_f2', 'iB', 'kB_f2', 'iB_f2']\n",
        "]\n",
        "\n",
        "for i in range(len(img_pairs_df2rw)):\n",
        "    fpA = img_pairs_df2rw.iloc[i].imgA\n",
        "    fpB = img_pairs_df2rw.iloc[i].imgB\n",
        "    \n",
        "    source_text_encoding = encodings.loc[file_id(fpA)].values[0:84].astype(np.float32)\n",
        "    target_text_encoding = encodings.loc[file_id(fpB)].values[0:84].astype(np.float32)\n",
        "    \n",
        "    source_keypoints = keypoints.loc[file_id(fpA)].values[2:38].astype(np.int32)\n",
        "    target_keypoints = keypoints.loc[file_id(fpB)].values[2:38].astype(np.int32)\n",
        "    \n",
        "    source_image = Image.open(f'{data_root}/{fpA}')\n",
        "    target_image = Image.open(f'{data_root}/{fpB}')\n",
        "    \n",
        "    iB_k = tips.benchmark(source_image, source_keypoints, target_keypoints)\n",
        "    out1 = tips.pipeline(source_image, source_keypoints, target_text_encoding, z)\n",
        "    out2 = tips.pipeline_full(source_image, source_text_encoding, target_text_encoding, z)\n",
        "    \n",
        "    images_dict = {\n",
        "        'iA': source_image.crop(bbox),\n",
        "        'iB': target_image.crop(bbox),\n",
        "        'iB_k0': iB_k.crop(bbox),\n",
        "        'iB_c1': out1['iB_c'].crop(bbox),\n",
        "        'iB_f1': out1['iB_f'].crop(bbox),\n",
        "        'iB_c2': out2['iB_c'].crop(bbox),\n",
        "        'iB_f2': out2['iB_f'].crop(bbox),\n",
        "        'kA': Image.fromarray(visualize_skeletons([source_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
        "        'kB': Image.fromarray(visualize_skeletons([target_keypoints], head_color=(100, 255, 100))).crop(bbox),\n",
        "        'kA_c2': Image.fromarray(visualize_skeletons([out2['kA_c']], head_color=(255, 100, 100))).crop(bbox),\n",
        "        'kA_f2': Image.fromarray(visualize_skeletons([out2['kA_f']], head_color=(100, 100, 255))).crop(bbox),\n",
        "        'kB_c1': Image.fromarray(visualize_skeletons([out1['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
        "        'kB_f1': Image.fromarray(visualize_skeletons([out1['kB_f']], head_color=(100, 100, 255))).crop(bbox),\n",
        "        'kB_c2': Image.fromarray(visualize_skeletons([out2['kB_c']], head_color=(255, 100, 100))).crop(bbox),\n",
        "        'kB_f2': Image.fromarray(visualize_skeletons([out2['kB_f']], head_color=(100, 100, 255))).crop(bbox),\n",
        "    }\n",
        "    \n",
        "    grid = visualize(images_dict, layout, True, font)\n",
        "    grid.save(f'{save_root_df2rw}/{file_id(fpA)}____{file_id(fpB)}.png')\n",
        "    print(f'\\r[DF2RW] Testing TIPS inference pipeline... {i+1}/{len(img_pairs_df2rw)}', end='')\n",
        "\n",
        "print('')\n",
        "\n",
        "!zip -rq tips_output_df2rw.zip $save_root_df2rw\n",
        "\n",
        "files.download('tips_output_df2rw.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH66_yKYR6v6"
      },
      "source": [
        "# ***Thank you for checking out TIPS!***\n"
      ]
    }
  ]
}
